This work demonstrates a practical and repeatable process for evaluating the safety of multi-robot systems controlled by Behavior Trees. By converting each robotâ€™s BT into a formal state-machine representation, composing those machines into a unified product system, and performing unsafe-state reachability analysis, we gain the ability to both detect and trace hazardous interactions that might otherwise go unnoticed until testing. This approach also supports iterative improvement: once unsafe paths are identified, modifications to the original Behavior Trees can be performed and re-verified until the behavior is confirmed safe.

Looking ahead, we aim to extend the methodology in several key directions. First, we will conduct a broader multi-robot investigation by building complete disassembly Behavior Trees for both the UR16e arm and the humanoid robot, then analyzing the full product state machine for safety flaws and logical inconsistencies. We also seek to automate the human-dependent refinement steps, including algorithmic detection of physically impossible transitions and automated identification of unsafe configurations based on workspace or task specifications. Integrating agentic AI methods may enable automatic modification of Behavior Trees followed by immediate verification through state-machine conversion, creating a closed-loop design and validation system.

Finally, we are interested in exploring treelikeness metrics and potential methods for converting or abstracting the product state machine back into a behavior-tree-like structure. Such research could provide new insights into how multiple BTs interact when composed and may lead to principled techniques for generating safe collaborative behaviors directly from their combined execution space.